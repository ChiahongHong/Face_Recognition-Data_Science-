{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  All Libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " N=400;\n",
    "data=np.zeros((N,4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Showing the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"/Users/lovepreetsingh/Desktop/All_Semesters/Spring_2018/CS_5661/Homework/HW3/Face/7.jpg\")\n",
    "plt.imshow(img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reading the images and building feature matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    img = mpimg.imread(\"/Users/lovepreetsingh/Desktop/All_Semesters/Spring_2018/CS_5661/Homework/HW3/Face/\"+str(i)+\".jpg\")\n",
    "    img_length = np.reshape(img,4096)\n",
    "    data[i]=np.copy(img_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reading the Label.csv and building Label Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_read = pd.read_csv('/Users/lovepreetsingh/Desktop/All_Semesters/Spring_2018/CS_5661/Homework/HW3/Face/label.csv')\n",
    "y = labels_read['Label']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Normalizing the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4096)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_feature=preprocess.scale(data)\n",
    "normalize_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Spliting the Normailzed Data into training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (300, 4096)\n",
      "y_train (300,)\n",
      "X_test (100, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalize_feature, y, test_size=0.25, random_state=5)\n",
    "print('X_train',X_train.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('X_test',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Applying PCA on the Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (300, 50)\n",
      "X_test (100, 50)\n"
     ]
    }
   ],
   "source": [
    "k = 50 # (k is the number of components (new features) after dimensionality reduction)\n",
    "my_pca = PCA(n_components = k)\n",
    "# X_Train is feature matrix of training set before dimensionality reduction,\n",
    "# X_Train_New is feature matrix of training set after dimensionality reduction:\n",
    "X_Train_new = my_pca. fit_transform(X_train)\n",
    "X_Test_new =  my_pca. transform(X_test)\n",
    "print('X_train', X_Train_new.shape)\n",
    "print('X_test',X_Test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# #f SVM implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model=svm.SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.0005, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_Train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "svm_predict=svm_model.predict(X_Test_new)\n",
    "score_svm = accuracy_score(y_test, svm_predict)\n",
    "print(score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 4 0]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_svm = metrics.confusion_matrix(y_test, svm_predict)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appling PCA again to get merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 50 # (k is the number of components (new features) after dimensionality reduction)\n",
    "my_pca = PCA(n_components = k)\n",
    "merge = my_pca. fit_transform(normalize_feature)\n",
    "merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Score 0.965\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [0.1, 1, 10, 100, 1e3, 5e3, 1e4, 5e4, 1e5]\n",
    "\n",
    "grid_dict = dict( C = param_grid)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',gamma=0.0005,random_state=1)\n",
    "\n",
    "grid = GridSearchCV(clf, grid_dict, cv=10, scoring='accuracy')\n",
    "grid.fit(merge,y)\n",
    "print('Best_Score',grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
